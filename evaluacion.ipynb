{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluación II\n",
    "\n",
    "\n",
    "En esta evaluación nos enfrentamos a un desafío emocionante de trabajar en un proyecto real para una empresa que realiza un estudio de universidades por el mundo. \n",
    "\n",
    "El proyecto tiene como objetivo identificar todas las universidades ubicadas en tres países específicos:\n",
    "\n",
    "    - Estados Unidos\n",
    "    - Canadá\n",
    "    - Argentina\n",
    "\n",
    "Para llevar a cabo esta tarea, utilizaremos la API de \"Universities Hipolabs\", una fuente confiable y completa de información sobre las universidades en todo el mundo. \n",
    "\n",
    "Con la ayuda de esta API, podemos acceder a una gran cantidad de datos relevantes, incluyendo el nombre de la universidad, la ciudad donde esta ubicada, el nombre de la institución y otra información importante que nos permitirá llevar a cabo un análisis detallado.\n",
    "\n",
    "\n",
    "Es importante tener en cuenta que este proyecto requerirá un conocimiento profundo de herramientas y técnicas de análisis de datos, así como habilidades en programación y manejo de APIs. \n",
    "\n",
    "También es importante tener una comprensión sólida de la estructura y organización de los datos, ya que esto nos permitirá hacer preguntas importantes y obtener respuestas significativas a partir de los datos.\n",
    "\n",
    "\n",
    "En resumen, esta prueba técnica ofrece una excelente oportunidad para demostrar habilidades y conocimientos en análisis de datos y programación, mientras se trabaja en un proyecto real y relevante para una empresa. \n",
    "\n",
    "Al finalizar del proyecto, esperamos obtener información valiosa que ayudará a la empresa a tomar decisiones más informadas sobre las universidades en los tres países objetivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell \n",
    "InteractiveShell.ast_node_interactivity = \"all\" \n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#import mysql.connector\n",
    "#from mysql.connector import errorcode\n",
    "\n",
    "from geopy.geocoders import Nominatim\n",
    "\n",
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Utilizando la API extraed toda la información que podáis de ella. \n",
    "\n",
    "    La url para hacer las llamadas es:\n",
    "    API_URL = \"http://universities.hipolabs.com/search?country=NOMBREPAIS\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hacemos una lista de los paises que nos interesan\n",
    "\n",
    "lista_paises = ['United States', 'Canada', 'Argentina']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'OK'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'OK'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'OK'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creamos un dataframe vacío\n",
    "df = pd.DataFrame()\n",
    "\n",
    "#iterando por la lista de paises vamos llamando a la API y adjuntamos los resultados al dataframe vacío\n",
    "for pais in lista_paises:\n",
    "    url = f'http://universities.hipolabs.com/search?country={pais}'\n",
    "    response = requests.get(url=url)\n",
    "    response.status_code\n",
    "    response.reason\n",
    "    df_pais = pd.DataFrame(response.json())\n",
    "    df = pd.concat([df, df_pais], axis = 0, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>domains</th>\n",
       "      <th>country</th>\n",
       "      <th>name</th>\n",
       "      <th>web_pages</th>\n",
       "      <th>state-province</th>\n",
       "      <th>alpha_two_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>[cheyney.edu]</td>\n",
       "      <td>United States</td>\n",
       "      <td>Cheyney University</td>\n",
       "      <td>[http://www.cheyney.edu/]</td>\n",
       "      <td>None</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3646</th>\n",
       "      <td>[mtsac.edu]</td>\n",
       "      <td>United States</td>\n",
       "      <td>Mt. San Antonio College</td>\n",
       "      <td>[http://www.mtsac.edu]</td>\n",
       "      <td>None</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3448</th>\n",
       "      <td>[wcupa.edu]</td>\n",
       "      <td>United States</td>\n",
       "      <td>West Chester University of Pennsylvania</td>\n",
       "      <td>[http://www.wcupa.edu/]</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1237</th>\n",
       "      <td>[ascc.edu]</td>\n",
       "      <td>United States</td>\n",
       "      <td>Alabama Southern Community College</td>\n",
       "      <td>[http://www.ascc.edu]</td>\n",
       "      <td>None</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4884</th>\n",
       "      <td>[uncu.edu.ar]</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>Universidad Nacional de Cuyo</td>\n",
       "      <td>[http://www.uncu.edu.ar/]</td>\n",
       "      <td>Mendoza</td>\n",
       "      <td>AR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2674</th>\n",
       "      <td>[fontbonne.edu]</td>\n",
       "      <td>United States</td>\n",
       "      <td>Fontbonne College</td>\n",
       "      <td>[http://www.fontbonne.edu/]</td>\n",
       "      <td>None</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1353</th>\n",
       "      <td>[imperial.edu]</td>\n",
       "      <td>United States</td>\n",
       "      <td>Imperial Valley College</td>\n",
       "      <td>[http://www.imperial.edu]</td>\n",
       "      <td>None</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>[drexel.edu]</td>\n",
       "      <td>United States</td>\n",
       "      <td>Drexel University</td>\n",
       "      <td>[http://www.drexel.edu/]</td>\n",
       "      <td>None</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1186</th>\n",
       "      <td>[wku.edu]</td>\n",
       "      <td>United States</td>\n",
       "      <td>Western Kentucky University</td>\n",
       "      <td>[http://www.wku.edu/]</td>\n",
       "      <td>None</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2767</th>\n",
       "      <td>[ivc.edu]</td>\n",
       "      <td>United States</td>\n",
       "      <td>Irvine Valley College</td>\n",
       "      <td>[http://www.ivc.edu/]</td>\n",
       "      <td>None</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              domains        country                                     name  \\\n",
       "274     [cheyney.edu]  United States                       Cheyney University   \n",
       "3646      [mtsac.edu]  United States                  Mt. San Antonio College   \n",
       "3448      [wcupa.edu]  United States  West Chester University of Pennsylvania   \n",
       "1237       [ascc.edu]  United States       Alabama Southern Community College   \n",
       "4884    [uncu.edu.ar]      Argentina             Universidad Nacional de Cuyo   \n",
       "2674  [fontbonne.edu]  United States                        Fontbonne College   \n",
       "1353   [imperial.edu]  United States                  Imperial Valley College   \n",
       "361      [drexel.edu]  United States                        Drexel University   \n",
       "1186        [wku.edu]  United States              Western Kentucky University   \n",
       "2767        [ivc.edu]  United States                    Irvine Valley College   \n",
       "\n",
       "                        web_pages state-province alpha_two_code  \n",
       "274     [http://www.cheyney.edu/]           None             US  \n",
       "3646       [http://www.mtsac.edu]           None             US  \n",
       "3448      [http://www.wcupa.edu/]   Pennsylvania             US  \n",
       "1237        [http://www.ascc.edu]           None             US  \n",
       "4884    [http://www.uncu.edu.ar/]        Mendoza             AR  \n",
       "2674  [http://www.fontbonne.edu/]           None             US  \n",
       "1353    [http://www.imperial.edu]           None             US  \n",
       "361      [http://www.drexel.edu/]           None             US  \n",
       "1186        [http://www.wku.edu/]           None             US  \n",
       "2767        [http://www.ivc.edu/]           None             US  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#visualizamos el dataframe resultante\n",
    "\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Una vez tengáis todos los datos de la API, deberéis realizar una serie de procesos de limpieza, estos incluyen:\n",
    "\n",
    "    -Cambiad los nombres de las columnas para homogeneizarlas, tenemos columnas que tienen - y otras _. Unifícalo para que todo vaya con _.\n",
    "\n",
    "    -La columna de domains nos da una información similar a la de web_pages. Eliminad la columna domains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'domains': 'domains',\n",
       " 'country': 'country',\n",
       " 'name': 'name',\n",
       " 'web_pages': 'web_pages',\n",
       " 'state-province': 'state_province',\n",
       " 'alpha_two_code': 'alpha_two_code'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lo primero que vamos a hacer es crear un diccionario con los nombres de las columnas y los nuevos nombres que queremos que tengan\n",
    "\n",
    "nuevas_columnas = {col:col.replace('-', '_') for col in df.columns}\n",
    "nuevas_columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cambiamos los nombres de las columnas\n",
    "\n",
    "df.rename(columns = nuevas_columnas, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Quitamos la columna 'domains'\n",
    "\n",
    "df.drop('domains', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Si exploramos la columna de web_pages, nos daremos cuenta que hay universidades, como por ejemplo la Universidad de \"Cégep de Saint-Jérôme\" de Canadá que en su columna de web_pages tiene más de un valor dentro de la lista. \n",
    "\n",
    "    Esto es poco práctico y puede llegar a no tener sentido. el objetivo de este ejercicio es que usando el método explode de pandas separéis cada elemento de la lista en una fila nueva."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>name</th>\n",
       "      <th>web_pages</th>\n",
       "      <th>state_province</th>\n",
       "      <th>alpha_two_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4536</th>\n",
       "      <td>Canada</td>\n",
       "      <td>Cégep de Saint-Jérôme</td>\n",
       "      <td>[https://www.cstj.qc.ca, https://ccmt.cstj.qc....</td>\n",
       "      <td>Quebec</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4686</th>\n",
       "      <td>Canada</td>\n",
       "      <td>Cégep de Saint-Jérôme</td>\n",
       "      <td>[https://www.cstj.qc.ca, https://ccmt.cstj.qc....</td>\n",
       "      <td>Quebec</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     country                   name  \\\n",
       "4536  Canada  Cégep de Saint-Jérôme   \n",
       "4686  Canada  Cégep de Saint-Jérôme   \n",
       "\n",
       "                                              web_pages state_province  \\\n",
       "4536  [https://www.cstj.qc.ca, https://ccmt.cstj.qc....         Quebec   \n",
       "4686  [https://www.cstj.qc.ca, https://ccmt.cstj.qc....         Quebec   \n",
       "\n",
       "     alpha_two_code  \n",
       "4536             CA  \n",
       "4686             CA  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Comprobamos cómo están separados los distintos valores\n",
    "\n",
    "df[df['name']== 'Cégep de Saint-Jérôme']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#aplicamos el método explode\n",
    "\n",
    "df = df.explode('web_pages')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Una vez hayáis realizado el explode, chequead si tenéis duplicados basándonos unicamente en el nombre de la universidad, en caso de que si, eliminandlos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2543"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Comprobamos si tenemos duplicados\n",
    "\n",
    "df.duplicated(subset = ['name']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Eliminamos los duplicados. Nos quedamos con el primer registro de cada uno de los duplicados\n",
    "\n",
    "df = df.drop_duplicates(['name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Si exploramos la columna de state_province veremos que hay universidades cuyo valor para esta columna es None. Cread una función para reemplazar los None por nulos de numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nulos(dato):\n",
    "    \"\"\"\n",
    "        Funcion que recibe un None y lo convierte a NaN\n",
    "        Args:\n",
    "            dato: es un None\n",
    "        Returns: \n",
    "            NaN\n",
    "    \"\"\"\n",
    "    if dato is None:\n",
    "        return np.nan\n",
    "    else:\n",
    "        return dato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aplicamos la función que hemos creado a la columna del dataframe\n",
    "\n",
    "df['state_province'] = df['state_province'].apply(nulos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Después del último cambio, os habréis dado cuenta que tenemos muchos valores nulos dentro de la columna de state_province, por lo que nuestro jefe nos pide que reemplacemos esos nulos por \"Unknow\". No nos piden ningún método especifico, asi que podremos usar el método que queramos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna('Unknown')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Ahora nuestros jefes nos piden que saquemos las coordenadas de las provincias donde están ubicadas las universidades. \n",
    "\n",
    "    Para eso nos piden que usemos la librería de geopy que aprendimos el día del repaso\n",
    "    \n",
    "    Para desarrollar este ejercicio deberéis:\n",
    "\n",
    "    -Sacar los valores únicos de la columna state_province."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    -Algunos de los valores que tenemos están con siglas, y deberéis reemplazarlos por lo siguiente:\n",
    "\n",
    "        NV: reemplazalo por Nevada\n",
    "        TX: reemplazalo por Texas\n",
    "        IN: reemplazalo por Indianapolis\n",
    "        CA: reemplazalo por California\n",
    "        VA: reemplazalo por Virginia\n",
    "        NY: reemplazalo por New York\n",
    "        MI: reemplazalo por Michigan\n",
    "        GA: reemplazalo por Georgia\n",
    "        ND: reemplazalo por North Dakota"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creamos un diccionario con los valores antiguos y los nuevos\n",
    "\n",
    "dict1 = {'NV' : 'Nevada',\n",
    "        'TX' : 'Texas',\n",
    "        'IN' : 'Indianapolis',\n",
    "        'CA' : 'California',\n",
    "        'VA' : 'Virginia',\n",
    "        'NY' : 'New York',\n",
    "        'MI' : 'Michigan',\n",
    "        'GA' : 'Georgia',\n",
    "        'ND' : 'North Dakota'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sustituimos los valores\n",
    "\n",
    "df['state_province'].replace(dict1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    -Otros valores que tenemos más formateados son y que deberemos reemplazar:\n",
    "\n",
    "        -New York, NY. Deberéis reemplazarlo por \"New York\"\n",
    "        \n",
    "        -'Buenos Aires', 'Ciudad Autónoma de Buenos Aires'. En este caso deberéis poner en ambos casos \"Buenos Aires\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dict2 = {'New York, NY': 'New York',\n",
    "         'Ciudad Autónoma de Buenos Aires' : 'Buenos Aires'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['state_province'].replace(dict2, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    -Una vez realizados los pasos anteriores, crea una lista con los valores únicos de las provincias de las universidades."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Algunos nombres nos devuelven localizaciones de otros paises así que los cambiamos\n",
    "dict3 = {'Georgia' : 'Georgia, USA',\n",
    "         'Córdoba' : 'Cordoba, Argentina',\n",
    "         'Formosa' : 'Formosa, Argentina',\n",
    "         'Santa Fe' : 'Santa Fe, Argentina',\n",
    "         'La Rioja' : 'La Rioja, Argentina',\n",
    "         'San Juan' : 'San Juan, Argentina',\n",
    "         'San Luis' : 'San Luis, Argentina'}\n",
    "\n",
    "df['state_province'].replace(dict3, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Unknown', 'Pennsylvania', 'Texas', 'Utah', 'Nevada', 'Iowa',\n",
       "       'Virginia', 'Indiana', 'Colorado', 'Ohio', 'Indianapolis',\n",
       "       'New York', 'California', 'Illinois', 'New Hampshire',\n",
       "       'North Carolina', 'South Carolina', 'Washington', 'Missouri',\n",
       "       'North Dakota', 'Michigan', 'Florida', 'Georgia, USA', 'Maine',\n",
       "       'Quebec', 'Ontario', 'Nova Scotia', 'British Columbia', 'Alberta',\n",
       "       'Manitoba', 'New Brunswick', 'Saskatchewan',\n",
       "       'Newfoundland and Labrador', 'Prince Edward Island', 'Yukon',\n",
       "       'Buenos Aires', 'Entre Ríos', 'Salta', 'Cordoba, Argentina',\n",
       "       'Mendoza', 'Santa Fé', 'Santiago Del Estero', 'Misiones',\n",
       "       'Catamarca', 'Formosa, Argentina', 'Jujuy', 'La Rioja, Argentina',\n",
       "       'La Pampa', 'San Juan, Argentina', 'San Luis, Argentina',\n",
       "       'Tucumán'], dtype=object)"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "provincias = df['state_province'].unique()\n",
    "provincias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    -Usando la API de geopy, extraed la latitud y la longitud de cada una de las provincias y almacenad los resultados en un dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state_province</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>40.9699889</td>\n",
       "      <td>-77.7278831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Texas</td>\n",
       "      <td>31.2638905</td>\n",
       "      <td>-98.5456116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Utah</td>\n",
       "      <td>39.4225192</td>\n",
       "      <td>-111.714358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nevada</td>\n",
       "      <td>39.5158825</td>\n",
       "      <td>-116.8537227</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  state_province    latitude     longitude\n",
       "0        Unknown     Unknown       Unknown\n",
       "0   Pennsylvania  40.9699889   -77.7278831\n",
       "0          Texas  31.2638905   -98.5456116\n",
       "0           Utah  39.4225192   -111.714358\n",
       "0         Nevada  39.5158825  -116.8537227"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geo = Nominatim(user_agent = 'catalina')\n",
    "df_local = pd.DataFrame()\n",
    "\n",
    "for prov in provincias:\n",
    "        \n",
    "    localizacion = geo.geocode(prov)\n",
    "    \n",
    "    if prov == 'Unknown':\n",
    "        df_prov = pd.DataFrame([localizacion.raw['name'], 'Unknown', 'Unknown']).T\n",
    "        df_local = pd.concat([df_local, df_prov], axis = 0)\n",
    "                               \n",
    "    else:\n",
    "        df_prov = pd.DataFrame([localizacion.raw['name'], localizacion.raw['lat'], localizacion.raw['lon']]).T\n",
    "        df_local = pd.concat([df_local, df_prov], axis = 0)      \n",
    "    \n",
    "df_local.set_axis(['state_province', 'latitude', 'longitude'], axis = 'columns', inplace = True)\n",
    "df_local.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    -Una vez que tengáis los datos del ejercicio anterior en un dataframe, unidlo con el de las universidades que hemos sacado de la API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>web_pages</th>\n",
       "      <th>alpha_two_code</th>\n",
       "      <th>state_province</th>\n",
       "      <th>name</th>\n",
       "      <th>country</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>'http://www.marywood.edu'</td>\n",
       "      <td>US</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Marywood University</td>\n",
       "      <td>United States</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'http://www.lindenwood.edu/'</td>\n",
       "      <td>US</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Lindenwood University</td>\n",
       "      <td>United States</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      web_pages alpha_two_code state_province  \\\n",
       "0     'http://www.marywood.edu'             US        Unknown   \n",
       "1  'http://www.lindenwood.edu/'             US        Unknown   \n",
       "\n",
       "                    name        country latitude longitude  \n",
       "0    Marywood University  United States  Unknown   Unknown  \n",
       "1  Lindenwood University  United States  Unknown   Unknown  "
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Ahora ya podemos juntar los dataframes\n",
    "\n",
    "df_final = df.merge(df_local, on = 'state_province')\n",
    "df_final.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Crea una BBDD en mysql que contenga las siguientes tablas:\n",
    "\n",
    "    Tabla países: donde encontraremos las siguientes columnas:\n",
    "\n",
    "        . idestado: primary key, integer, autoincremental\n",
    "        . nombre_pais: varchar\n",
    "        . nombre_provincia: varchar\n",
    "        . latitud: decimal\n",
    "        . longitud: decimal\n",
    "    Tabla universidades: donde encontraremos las siguientes columnas:\n",
    "    \n",
    "        . iduniversidades: primary key, integer, autoincremental\n",
    "        . nombre_universidad: varchar\n",
    "        . pagina_web: varchar\n",
    "        . paises_idestado: foreing key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Conectamos con la base de datos\n",
    "\n",
    "mydb = mysql.connector.connect(\n",
    "        host=\"127.0.0.1\",\n",
    "        user=\"root\",\n",
    "        password=\"AlumnaAdalab\", \n",
    "        auth_plugin = 'mysql_native_password')\n",
    "   \n",
    "mycursor = mydb.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creamos la base de datos\n",
    "\n",
    "mycursor.execute(\"CREATE DATABASE IF NOT EXISTS `Universidades`\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creamos las tablas\n",
    "\n",
    "mycursor.execute =('''\n",
    "CREATE TABLE IF NOT EXISTS `universidades`.`provincias` (\n",
    "  `id_provincia` INT NOT NULL AUTO_INCREMENT,\n",
    "  `nombre_provincia` VARCHAR,\n",
    "  `nombre_pais` VARCHAR,\n",
    "  `latitud` DECIMAL,\n",
    "  `longitud` DECIMAL,\n",
    "  PRIMARY KEY (`id_provincia`),   \n",
    "  ENGINE = InnoDB;''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mycursor.execute = ('''\n",
    "CREATE TABLE IF NOT EXISTS `universidades`.`universidades` (\n",
    "  `id_universidad` INT NOT NULL AUTO_INCREMENT,\n",
    "  `nombre_universidad` VARCHAR,\n",
    "  `pagina_web` VARCHAR,\n",
    "  `id_provincia` INT,                                                            \n",
    "  PRIMARY KEY (`id_universidad`),                       \n",
    "  CONSTRAINT `fk_provincias_universidades`                   \n",
    "    FOREIGN KEY (`id_provincia`)                                                  \n",
    "    REFERENCES `universidades`.`provincias` (`id_provincia`),\n",
    "ENGINE = InnoDB;''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Introduce todo el código que habéis ido creando en funciones, siguiendo la misma lógica que hemos seguido en los pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creamos la funcion que nos permite conectarnos a la API y obtener datos\n",
    "\n",
    "def conexion_API(paises):\n",
    "    \"\"\"\n",
    "        Funcion que nos permite conectar con la API\n",
    "        y obtener un dataframe con los datos solicitados\n",
    "        Args:\n",
    "            paises: List\n",
    "        Returns: dataframe\n",
    "            \n",
    "    \"\"\"\n",
    "    df = pd.DataFrame()\n",
    "    for pais in paises:\n",
    "        url = f'http://universities.hipolabs.com/search?country={pais}'\n",
    "        response = requests.get(url=url)\n",
    "        response.status_code\n",
    "        response.reason\n",
    "        df_pais = pd.DataFrame(response.json())\n",
    "        df = pd.concat([df, df_pais], axis = 0, ignore_index = True)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creamos la funcion de limpieza del dataframe\n",
    "\n",
    "def limpieza(df):\n",
    "    \"\"\"\n",
    "        Funcion que nos permite limpiar un dataframe\n",
    "        Unificando nombre de columnas\n",
    "        Borrar columna 'domains' redundante\n",
    "        Separa informacion de la columna 'web_pages'\n",
    "        Eliminar duplicados\n",
    "        Args:\n",
    "            df: dataframe\n",
    "            \n",
    "        Returns: dataframe limpio\n",
    "            \n",
    "    \"\"\"\n",
    "    \n",
    "    df.rename(columns = {col:col.replace('-', '_') for col in df.columns}, inplace = True)\n",
    "    df.drop('domains', axis = 1, inplace = True)\n",
    "    df['web_pages'] = df['web_pages'].astype(dtype = 'str', errors = 'raise')\n",
    "    df['web_pages'] = df['web_pages'].str.split(',')\n",
    "    df = df.explode('web_pages')\n",
    "    df = df.drop_duplicates(['name'])\n",
    "    df['web_pages'] = df['web_pages'].str.replace('[', '').str.replace(']', '')\n",
    "    \n",
    "    \n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#funcion para el tratamiento de nulos del dataframe\n",
    "\n",
    "def limpiar_nulos(df):\n",
    "    \"\"\"\n",
    "        Funcion que nos permite imputar los nulos del dataframe\n",
    "        Args:\n",
    "            df: dataframe\n",
    "            \n",
    "        Returns: dataframe limpio\n",
    "            \n",
    "    \"\"\"\n",
    "    for indice in range(df.shape[0]):\n",
    "        if df['state_province'][indice] is None:\n",
    "            df['state_province'][indice] = np.nan\n",
    "        else:\n",
    "            continue\n",
    "    \n",
    "    df = df.fillna('Unknown')\n",
    "    \n",
    "    return df\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#funcion para añadir las coordenadas de las universidades\n",
    "\n",
    "def coordenadas(user_agent, lista_provincias, df_universidades):\n",
    "    \"\"\"\n",
    "        Funcion que nos permite obtener las coordenadas de las provincias en las que \n",
    "        estan las universidades usando geopy\n",
    "        Args:\n",
    "            user_agent: String\n",
    "            lista_provincias: lista\n",
    "            df_universidades: dataframe\n",
    "        Returns: dataframe con las coordenadas añadidas\n",
    "            \n",
    "    \"\"\"\n",
    "    geo = Nominatim(user_agent = user_agent)\n",
    "    df_local = pd.DataFrame()    \n",
    "\n",
    "    for prov in lista_provincias:\n",
    "            \n",
    "        localizacion = geo.geocode(prov)\n",
    "        \n",
    "        if prov == 'Unknown':\n",
    "            df_prov = pd.DataFrame([localizacion.raw['name'], 'Unknown', 'Unknown']).T\n",
    "            df_local = pd.concat([df_local, df_prov], axis = 0)\n",
    "                                \n",
    "        else:\n",
    "            df_prov = pd.DataFrame([localizacion.raw['name'], localizacion.raw['lat'], localizacion.raw['lon']]).T\n",
    "            df_local = pd.concat([df_local, df_prov], axis = 0)      \n",
    "        \n",
    "    df_local.set_axis(['state_province', 'latitude', 'longitude'], axis = 'columns', inplace = True)\n",
    "    df_local.head()\n",
    "    \n",
    "    df_final = df_universidades.merge(df_local, on = 'state_province')\n",
    "    \n",
    "    return df_final\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creamos la funcion para crear una base de datos\n",
    "\n",
    "def crear_bbdd(nombre_bbdd, contraseña):\n",
    "    \"\"\"\n",
    "        Funcion que nos permite conectar con un servidor\n",
    "        MySQL y crear una nueva base de datos\n",
    "        Args:\n",
    "            nombre_bbdd: String\n",
    "            contraseña: string\n",
    "        Returns: cursor\n",
    "            \n",
    "    \"\"\"\n",
    "    mydb = mysql.connector.connect(\n",
    "        host=\"127.0.0.1\",\n",
    "        user=\"root\",\n",
    "        password=contraseña,\n",
    "        auth_plugin = 'mysql_native_password') \n",
    "    print(\"Conexión realizada con éxito\")    \n",
    "    mycursor = mydb.cursor()    \n",
    "    try:\n",
    "        mycursor.execute(f\"CREATE DATABASE IF NOT EXISTS {nombre_bbdd};\")\n",
    "        print(mycursor)\n",
    "    except mysql.connector.Error as err:\n",
    "        print(err)\n",
    "        print(\"Error Code:\", err.errno)\n",
    "        print(\"SQLSTATE\", err.sqlstate)\n",
    "        print(\"Message\", err.msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creamos la funcion para crear e insertar tablas\n",
    "\n",
    "def crear_insertar_tabla(nombre_bbdd, contraseña, query): \n",
    "    \"\"\"\n",
    "        Funcion que nos permite conectar con un servidor\n",
    "        MySQL y ejecutar una query\n",
    "        Args:\n",
    "            nombre_bbdd: string\n",
    "            contraseña: string\n",
    "            query: string\n",
    "        Returns: sin return\n",
    "            \n",
    "    \"\"\"\n",
    "    cnx = mysql.connector.connect(user='root', password=f\"{contraseña}\",\n",
    "                                     host='127.0.0.1', database=f\"{nombre_bbdd}\",\n",
    "                                     auth_plugin = 'mysql_native_password')\n",
    "   \n",
    "    mycursor = cnx.cursor() \n",
    "    try:\n",
    "        mycursor.execute(query)\n",
    "        cnx.commit()\n",
    "    \n",
    "    except mysql.connector.Error as err:\n",
    "        print(err)\n",
    "        print(\"Error Code:\", err.errno)\n",
    "        print(\"SQLSTATE\", err.sqlstate)\n",
    "        print(\"Message\", err.msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. BONUS\n",
    "\n",
    "    -Introduce los datos en la BBDD de SQL.\n",
    "    \n",
    "    -Crea una clase con todo el código generado en esta evaluación."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
